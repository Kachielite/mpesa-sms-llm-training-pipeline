{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MPESA SMS Data Preparation Guide for Fine-tuning LLMs\n",
    "This guide explains how to transform raw MPESA SMS messages into training data for fine-tuning LLMs. It covers both basic models and instruct/chat models, with steps for cleaning, anonymizing, and formatting data. The goal is to extract:\n",
    "\n",
    "We need to extract the key fields:\n",
    "- **transaction_id**\n",
    "- **amount**\n",
    "- **transaction_type** (sent, received, withdrawn, failed)\n",
    "- **counterparty**\n",
    "- **date_time**\n",
    "- **balance**\n"
   ],
   "id": "2fada22dbcb0458"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "We will be using raw MPESA SMS messages as input. The messages typically contain information about transactions such as money sent, received, withdrawn, or failed transactions.\n",
    "\n",
    "We will follow these steps:\n",
    "1. Data Collection\n",
    "2. Data Anonymization\n",
    "3. Data Parsing\n",
    "4. Data Formatting\n",
    "5. Data Validation"
   ],
   "id": "d0a552f70f59cc9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Data Collection\n",
    "Gather all MPESA SMS messages. This can be done by exporting SMS data from your phone or using an SMS backup app.\n",
    "\n"
   ],
   "id": "43fc3ec3cd249bd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def load_sms_from_xml(xml_file: str):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    sms_list = []\n",
    "    for sms in root.findall(\"sms\"):\n",
    "        body = sms.get(\"body\")\n",
    "        date = sms.get(\"readable_date\")\n",
    "        sms_list.append({\"sms_text\": body, \"date\": date})\n",
    "\n",
    "    df = pd.DataFrame(sms_list)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df = load_sms_from_xml(\"../data/mpesa-sms.xml\")\n",
    "print(df.head())\n"
   ],
   "id": "22c7e1c5afb610e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Data Anonymization\n",
    "To protect privacy, we will anonymize sensitive information such as phone numbers and names. We can replace them with placeholders like `<PHONE_NUMBER>` and `<NAME>`."
   ],
   "id": "72b9e0fd0a6979f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import uuid\n",
    "\n",
    "def anonymize_sms(sms: str):\n",
    "    # Mask phone numbers\n",
    "    sms = re.sub(r\"\\b(?:\\+254|0)?7\\d{8}\\b\", \"XXXXXXX\", sms)\n",
    "\n",
    "    # Replace names with CUSTOMER_<uuid> (same name in one SMS gets same UUID)\n",
    "    name_uuid_map = {}\n",
    "    def replace_name(match):\n",
    "        name = match.group(1)\n",
    "        if name not in name_uuid_map:\n",
    "            name_uuid_map[name] = f\"CUSTOMER_{uuid.uuid4().hex[:8].upper()}\"\n",
    "        return f\"{match.group(0).split()[0]} {name_uuid_map[name]}\"\n",
    "\n",
    "    sms = re.sub(r\"from\\s+([A-Za-z]+(?:\\s+[A-ZaZ]+)*)\", replace_name, sms, flags=re.IGNORECASE)\n",
    "    sms = re.sub(r\"to\\s+([A-Za-z]+(?:\\s+[A-ZaZ]+)*)\", replace_name, sms, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace Agent numbers\n",
    "    sms = re.sub(r\"Agent\\s+(\\d+)\", r\"Agent_\\1\", sms, flags=re.IGNORECASE)\n",
    "\n",
    "    return sms\n",
    "\n",
    "# Example usage\n",
    "df[\"anonymized_sms\"] = df[\"sms_text\"].apply(anonymize_sms)\n",
    "print(df[[\"sms_text\", \"anonymized_sms\"]].head())"
   ],
   "id": "e8a7329682fe1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Data Parsing\n",
    "Next, we will parse the anonymized SMS messages to extract key fields such as transaction ID, amount, transaction type, counterparty, date/time, and balance."
   ],
   "id": "24db97281bed83d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def parse_mpesa_sms(sms: str, date_time: str = None):\n",
    "    transaction_id = sms.split()[0] if sms else None\n",
    "\n",
    "    amount_match = re.search(r\"Ksh\\s*([\\d,]+(?:\\.\\d{2})?)\", sms)\n",
    "    amount = amount_match.group(1).replace(\",\", \"\") if amount_match else None\n",
    "\n",
    "    # Comprehensive transaction type extraction\n",
    "    transaction_type = \"unknown\"\n",
    "    transaction_types = [\n",
    "        (r\"received from\", \"received\"),\n",
    "        (r\"sent to\", \"sent\"),\n",
    "        (r\"withdrew at\", \"withdrawn\"),\n",
    "        (r\"withdrawn at\", \"withdrawn\"),\n",
    "        (r\"failed\", \"failed\"),\n",
    "        (r\"buy goods and services at\", \"buy_goods\"),\n",
    "        (r\"paid to\", \"paybill\"),\n",
    "        (r\"airtime purchase\", \"airtime\"),\n",
    "        (r\"bought .*? of airtime\", \"airtime\"),\n",
    "        (r\"deposited to\", \"deposit\"),\n",
    "        (r\"reversed\", \"reversal\"),\n",
    "        (r\"bill payment to\", \"bill_payment\"),\n",
    "        (r\"loan disbursed\", \"loan\"),\n",
    "        (r\"fuliza\", \"fuliza\"),\n",
    "        (r\"received for account\", \"received_account\"),\n",
    "        (r\"transferred to\", \"transferred\"),\n",
    "        (r\"transferred from\", \"transferred_in\"),\n",
    "    ]\n",
    "    for pattern, ttype in transaction_types:\n",
    "        if re.search(pattern, sms, re.IGNORECASE):\n",
    "            transaction_type = ttype\n",
    "            break\n",
    "\n",
    "    # Improved counterparty extraction\n",
    "    counterparty = None\n",
    "    if transaction_type in [\"received\", \"sent\"]:\n",
    "        match = re.search(r\"(?:from|to)\\s+(CUSTOMER_\\w+|AGENT_\\w+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1)\n",
    "    elif transaction_type == \"withdrawn\":\n",
    "        match = re.search(r\"AGENT_(\\w+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = f\"AGENT_{match.group(1)}\"\n",
    "    elif transaction_type == \"buy_goods\":\n",
    "        match = re.search(r\"buy goods and services at ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    elif transaction_type == \"paybill\":\n",
    "        match = re.search(r\"paid to ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    elif transaction_type == \"airtime\":\n",
    "        counterparty = \"self\"\n",
    "    elif transaction_type == \"deposit\":\n",
    "        match = re.search(r\"deposited to ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    elif transaction_type == \"bill_payment\":\n",
    "        match = re.search(r\"bill payment to ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    elif transaction_type == \"transferred\":\n",
    "        match = re.search(r\"transferred to ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    elif transaction_type == \"transferred_in\":\n",
    "        match = re.search(r\"transferred from ([A-Za-z0-9_\\- ]+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1).strip()\n",
    "    # fallback: try to find any CUSTOMER_ or AGENT_ if not already found\n",
    "    if not counterparty:\n",
    "        match = re.search(r\"(CUSTOMER_\\w+|AGENT_\\w+)\", sms, re.IGNORECASE)\n",
    "        if match:\n",
    "            counterparty = match.group(1)\n",
    "\n",
    "    # FIXED: Use date_time from XML if provided, else try to extract from SMS with improved patterns\n",
    "    if date_time:\n",
    "        parsed_date_time = date_time\n",
    "    else:\n",
    "        # Fixed date/time extraction - multiple patterns to handle different formats\n",
    "        date_patterns = [\n",
    "            # Pattern 1: d/m/yy at h:mm AM/PM (single digits allowed)\n",
    "            r\"(\\d{1,2}/\\d{1,2}/\\d{2}\\s+at\\s+\\d{1,2}:\\d{2}\\s+(?:AM|PM))\",\n",
    "            # Pattern 2: on d/m/yy at h:mm AM/PM\n",
    "            r\"on\\s+(\\d{1,2}/\\d{1,2}/\\d{2}\\s+at\\s+\\d{1,2}:\\d{2}\\s+(?:AM|PM))\",\n",
    "            # Pattern 3: Just the date and time part\n",
    "            r\"(\\d{1,2}/\\d{1,2}/\\d{2}.*?\\d{1,2}:\\d{2}\\s+(?:AM|PM))\",\n",
    "        ]\n",
    "\n",
    "        parsed_date_time = None\n",
    "        for pattern in date_patterns:\n",
    "            date_match = re.search(pattern, sms)\n",
    "            if date_match:\n",
    "                parsed_date_time = date_match.group(1).strip()\n",
    "                break\n",
    "\n",
    "    balance_match = re.search(r\"balance.*?Ksh\\s*([\\d,]+(?:\\.\\d{2})?)\", sms, re.IGNORECASE)\n",
    "    balance = balance_match.group(1).replace(\",\", \"\") if balance_match else None\n",
    "\n",
    "    return {\n",
    "        \"transaction_id\": transaction_id,\n",
    "        \"amount\": amount,\n",
    "        \"transaction_type\": transaction_type,\n",
    "        \"counterparty\": counterparty,\n",
    "        \"date_time\": parsed_date_time,\n",
    "        \"balance\": balance\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "parsed_data = [parse_mpesa_sms(row[\"anonymized_sms\"], row[\"date\"]) for _, row in df.iterrows()]\n",
    "parsed_df = pd.DataFrame(parsed_data)\n",
    "print(parsed_df.head())"
   ],
   "id": "7a5ecc635ad13a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Data Formatting\n",
    "We will format the parsed data into JSONL format for basic models and a conversational format for instruct/chat models."
   ],
   "id": "3dab1e25aae8ba4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def prepare_from_xml(xml_file: str, output_file: str, mode=\"basic\"):\n",
    "    df = load_sms_from_xml(xml_file)\n",
    "    records = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        sms = row[\"sms_text\"]\n",
    "        anonymized_sms = anonymize_sms(sms)\n",
    "        parsed = parse_mpesa_sms(anonymized_sms)\n",
    "\n",
    "        if mode == \"basic\":\n",
    "            training_example = {\n",
    "                \"input\": anonymized_sms,\n",
    "                \"output\": json.dumps(parsed)\n",
    "            }\n",
    "        else:  # instruct mode\n",
    "            training_example = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f'Extract transaction details from the following SMS:\\n\"{anonymized_sms}\"'\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": json.dumps(parsed)\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "        records.append(training_example)\n",
    "\n",
    "    # Print a sample of the formatted data\n",
    "    print(f\"\\nSample for mode='{mode}':\\n\", json.dumps(records[0], indent=2))\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for rec in records:\n",
    "            f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "# Example usage\n",
    "Path(\"../output\").mkdir(exist_ok=True)\n",
    "prepare_from_xml(\"../data/mpesa-sms.xml\", \"../output/mpesa_basic.jsonl\", mode=\"basic\")\n",
    "prepare_from_xml(\"../data/mpesa-sms.xml\", \"../output/mpesa_instruct.jsonl\", mode=\"instruct\")"
   ],
   "id": "215ed067b944814d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Push Anonymized Data to Hugging Face Hub\n",
    "Now that the data is anonymized and formatted, you can upload it to the Hugging Face Hub for sharing or fine-tuning.\n"
   ],
   "id": "d3038b48d308a406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "repo_id = os.getenv(\"REPO_ID\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# 1. Login to Hugging Face (run this once per session)\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "else:\n",
    "    raise ValueError(\"HF_TOKEN not set in .env file.\")\n",
    "\n",
    "# 2. Set your repo name and path to files\n",
    "files_to_upload = [\n",
    "    \"output/mpesa_basic.jsonl\",\n",
    "    \"output/mpesa_instruct.jsonl\"\n",
    "]\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# 3. Create repo if it doesn't exist\n",
    "try:\n",
    "    api.create_repo(repo_id, repo_type=\"dataset\", private=False, exist_ok=True)\n",
    "    print(f\"Repo '{repo_id}' created or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating repo: {e}\")\n",
    "    # If repo creation fails, try to continue with upload (repo might already exist)\n",
    "    print(\"Continuing with file upload...\")\n",
    "\n",
    "# 4. Upload files\n",
    "for file in files_to_upload:\n",
    "    try:\n",
    "        print(f\"Uploading {file} to {repo_id}...\")\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=file,\n",
    "            path_in_repo=file.split(\"/\", 1)[-1],\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"dataset\"\n",
    "        )\n",
    "        print(f\"Uploaded {file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {file}: {e}\")\n",
    "\n",
    "print(f\"Process completed. Check your dataset at: https://huggingface.co/datasets/{repo_id}\")\n"
   ],
   "id": "dbfe00fadc46ce71",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
